<!doctype html>
<html>
  <head>
    <script type="text/javascript" src="https://livejs.com/live.js"></script>
    <script>
      function resizeIframe(obj) {
        obj.style.height =
          obj.contentWindow.document.documentElement.scrollHeight + "px";
      }
    </script>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"
    />

    <title>Ethical Considerations of Uncensored LLMs - Dr. Aoife Hughes</title>

    <link rel="stylesheet" href="dist/reset.css" />
    <link rel="stylesheet" href="dist/reveal.css" />
    <link rel="stylesheet" href="dist/theme/white.css" />

    <link rel="stylesheet" href="plugin/highlight/nord.css" />
    <style>
      .reveal h1,
      .reveal h2,
      .reveal h3,
      .reveal h4,
      .reveal h5 {
        text-transform: none;
      }

      .item1 {
        grid-area: morrisGroup;
      }

      .item2 {
        grid-area: faulknerGroup;
      }

      .item3 {
        grid-area: jic;
      }

      .item4 {
        grid-area: dtp;
      }

      .grid-container {
        display: grid;
        grid-template-areas: "morrisGroup faulknerGroup jic" "morrisGroup faulknerGroup dtp";
        grid-gap: 10px;
        padding: 10px;
      }

      .grid-container > div {
        text-align: center;
        padding: 20px 0;
        font-size: 30px;
      }

      .header-right {
        position: absolute;
        bottom: 0%;
        left: 0%;
      }

      .grid-images1 {
        display: grid;
        grid-template-columns: auto;
        padding: 10px;
      }

      .grid-images2 {
        display: grid;
        grid-template-columns: auto auto;
        padding: 10px;
      }

      .grid-images3 {
        display: grid;
        grid-template-columns: auto auto auto;
        padding: 10px;
      }

      .grid-images4 {
        display: grid;
        grid-template-columns: auto auto auto auto;
        padding: 0px;
      }

      .grid-images-item {
        padding: 10px;
        font-size: 30px;
        text-align: center;
      }
      footer {
        margin-top: 50px; /* Adjust this value to increase or decrease space */
        font-size: 0.75em; /* Makes the footer text smaller */
      }
    </style>
  </head>

  <body>
    <div class="reveal">
      <div class="slides">
        <section>
          <h1>Ethical Considerations of Uncensored LLMs</h1>
          <p>Dr. Aoife Hughes, The Alan Turing Institute</p>
        </section>

        <section>
          <section>
            <h1>Introduction</h1>
            <ul>
              <li class="fragment">
                Exploring the impact and implications of Large Language Models
                in modern computing.
              </li>
              <li class="fragment">
                Understanding the balance between unrestricted knowledge access
                and ethical responsibilities.
              </li>
            </ul>
          </section>
        </section>

        <section>
          <section>
            <h2>ChatGPT Content Policy</h2>
            <ol>
              <li class="fragment">
                No generation of explicit or offensive content: Avoids creating
                or promoting sexually explicit, violent, or offensive content.
              </li>
              <li class="fragment">
                Respect for privacy: Does not discuss or speculate on private
                information about individuals.
              </li>
              <li class="fragment">
                No promotion of harmful or illegal activities: Does not provide
                guidance on illegal or harmful activities.
              </li>
              <li class="fragment">
                No medical or legal advice: Does not offer professional medical
                or legal advice, recommends consulting qualified professionals.
              </li>
              <li class="fragment">
                No financial advice: Avoids giving personalized financial
                advice.
              </li>
              <li class="fragment">
                No generating or spreading misinformation: Strives to provide
                accurate information and correct misinformation.
              </li>
              <li class="fragment">
                Respect for intellectual property: Does not generate content
                that infringes on others' intellectual property rights.
              </li>
              <li class="fragment">
                Inclusivity and sensitivity: Generates content that is
                inclusive, respectful, and sensitive to diverse audiences and
                topics.
              </li>
            </ol>
          </section>

          <section>
            <h2>Downsides of ChatGPT Content Policy</h2>
            <ol>
              <li class="fragment">
                Limited Range in Certain Topics: Restrictions on explicit
                content, legal, medical, and financial advice may limit depth in
                these areas.
              </li>
              <li class="fragment">
                Over-Cautiousness in Responses: Efforts to avoid misinformation
                or harmful advice can lead to overly cautious or vague
                responses.
              </li>
              <li class="fragment">
                Restriction on Creative Content: Intellectual property
                limitations can restrict discussions about popular culture or
                creative inquiries.
              </li>
              <li class="fragment">
                Potential Over-Moderation: Focus on inclusivity and avoiding
                offense may result in avoiding important but sensitive
                discussions.
              </li>
              <li class="fragment">
                Lack of Personalization in Advice: Avoidance of personalized
                advice can limit the usefulness for specific individual
                guidance.
              </li>
              <li class="fragment">
                Challenges in Identifying Misinformation: The AI's ability to
                identify and navigate misinformation is not infallible.
              </li>
              <li class="fragment">
                Limitations in Discussing Current Events: Limited ability to
                discuss recent events or developments due to training cut-off.
              </li>
            </ol>
          </section>
        </section>

        <section>
          <section data-auto-animate>
            <img
              src="./images/chatGPT_murder.png"
              style="width: 50%; float: left"
            />
          </section>
          <section data-auto-animate>
            <img
              src="./images/chatGPT_murder.png"
              style="width: 50%; float: left"
            />
            <img
              src="./images/wizard_murder.png"
              style="width: 50%; float: right"
            />
          </section>
        </section>

        <section>
          <section data-auto-animate>
            <img
              src="./images/chatGPT_tooth.png"
              style="width: 50%; float: left"
            />
          </section>
          <section data-auto-animate>
            <img
              src="./images/chatGPT_tooth.png"
              style="width: 50%; float: left"
            />
            <img
              src="./images/wizard_tooth.png"
              style="width: 50%; float: right"
            />
          </section>
        </section>

        <section>
          <!-- Slide 1 -->
          <section data-auto-animate>
            <h2>Overview of closely relevant Papers</h2>
            <p>
              Exploring recent research papers and their implications on the
              ethics of uncensored Large Language Models (LLMs).
            </p>
            <p>
              <small
                >Focus: AI in Medicine, Toxicity in LMs, Jailbreak
                Prompts</small
              >
            </p>
            <footer></footer>
          </section>

          <!-- Slide 2 -->
          <section data-auto-animate>
            <h3>AI-assisted Medical Education: ChatGPT on USMLE</h3>
            <ul>
              <li class="fragment">
                Evaluation of ChatGPT's performance on USMLE exams.
              </li>
              <li class="fragment">
                Performance near passing threshold without specialized training.
              </li>
              <li class="fragment">
                Potential in medical education and clinical decision-making.
              </li>
              <li class="fragment">
                Raises questions about reliance on AI in critical fields.
              </li>
              <li class="fragment">
                Importance of trust and explainability in AI for medicine.
              </li>
              <li class="fragment">
                Strangely, doesn't mention censorship issues!
              </li>
            </ul>
            <footer>
              <small
                >Kung, T. H., et al., "Performance of ChatGPT on USMLE,"
                2023.[18â€ source]</small
              >
            </footer>
          </section>

          <!-- Slide 3 -->
          <section data-auto-animate>
            <h3>Toxicity in Language Models and Detoxification</h3>
            <ul>
              <li class="fragment">
                Study on the reproduction or amplification of toxic language by
                LMs.
              </li>
              <li class="fragment">
                Impact of prompts, decoding strategies, and training corpora on
                toxicity.
              </li>
              <li class="fragment">
                Proposes self-detoxification method for reducing toxicity.
              </li>
              <li class="fragment">
                Addresses the challenge of balancing toxicity reduction and
                content diversity.
              </li>
              <li class="fragment">
                Risks of marginalizing minority voices during detoxification.
              </li>
            </ul>
            <footer>
              <small
                >"Study on Toxicity in Language Models,"
                2023.[27â€ source][28â€ source]</small
              >
            </footer>
          </section>

          <!-- Slide 4 -->
          <section data-auto-animate>
            <h3>Jailbreak Prompts in Large Language Models</h3>
            <ul>
              <li class="fragment">
                First measurement study on jailbreak prompts to manipulate LLMs.
              </li>
              <li class="fragment">
                Analysis of over 6000 prompts from multiple platforms.
              </li>
              <li class="fragment">
                Evaluation of prompt effectiveness against various LLMs and
                safeguards.
              </li>
              <li class="fragment">
                Identifies evolving threat landscape of jailbreak prompts.
              </li>
              <li class="fragment">
                Highlights vulnerabilities of LLMs to adversarial manipulation.
              </li>
            </ul>
            <footer>
              <small
                >Shen, X., et al., "Characterizing Jailbreak Prompts in LLMs,"
                2023.[45â€ source][46â€ source]</small
              >
            </footer>
          </section>

          <!-- Slide 5 -->
          <section data-auto-animate>
            <h2>Ethical Considerations for Uncensored LLMs</h2>
            <ul>
              <li class="fragment">
                Medical Misinformation: Potential misuse in medical advice.
              </li>
              <li class="fragment">
                Toxicity and Bias: Challenge in reducing LLMs' toxicity.
              </li>
              <li class="fragment">
                Manipulation and Misuse: Vulnerability to adversarial jailbreak
                prompts.
              </li>
              <li class="fragment">
                Evolving Threats: Dynamic nature of adversarial attacks on LLMs.
              </li>
            </ul>
            <footer></footer>
          </section>

          <!-- Slide 6 -->
          <section data-auto-animate>
            <h2>Risks and Mitigation Strategies</h2>
            <ul>
              <li class="fragment">
                Discussing potential risks associated with each ethical concern.
              </li>
              <li class="fragment">
                Proposing mitigation strategies: Improved safety protocols,
                regular model updates, user awareness.
              </li>
              <li class="fragment">
                Challenges in balancing ethical use and technological
                advancement of LLMs.
              </li>
            </ul>
            <footer></footer>
          </section>
        </section>

        <section>
          <h2>Ethical Challenges</h2>
          <p>
            Addressing the inherent biases in LLMs: How data sources shape AI
            perspectives.
          </p>
          <p>
            The dilemma of censorship: Balancing freedom of speech with
            responsible content moderation.
          </p>
        </section>

        <section>
          <h2>Pros of Uncensored LLMs</h2>
          <ul>
            <li>
              Enhanced Creativity and Innovation: Unfettered access to diverse
              information fosters new ideas.
            </li>
            <li>
              Comprehensive Knowledge Base: Ability to process and analyze
              extensive datasets without restrictions.
            </li>
            <li>
              Unbiased Data Interpretation: Reduced risk of filtering or
              altering information based on subjective criteria.
            </li>
          </ul>
        </section>

        <section>
          <h2>Cons of Uncensored LLMs</h2>
          <ul>
            <li>
              Spread of Misinformation: Increased risk of distributing false or
              harmful content.
            </li>
            <li>
              Amplification of Harmful Biases: Unchecked propagation of existing
              societal biases in data.
            </li>
            <li>
              Ethical and Moral Risks: Challenges in defining and enforcing
              ethical guidelines for AI content.
            </li>
          </ul>
        </section>

        <section>
          <h2>Case Studies</h2>
          <p>
            Analysis of AI-driven content curation in social media platforms:
            Balancing user engagement with factual accuracy.
          </p>
          <p>
            Exploring the role of LLMs in news aggregation and the challenges in
            ensuring balanced reporting.
          </p>
        </section>

        <section>
          <h2>Conclusion</h2>
          <p>
            Summarizing the ethical landscape of LLMs and their role in shaping
            the future of AI.
          </p>
          <p>
            Discussing potential paths forward for responsibly integrating LLMs
            in various domains.
          </p>
        </section>

        <section>
          <h2>Q&A</h2>
        </section>
      </div>
    </div>

    <script src="dist/reveal.js"></script>
    <script src="plugin/notes/notes.js"></script>
    <script src="plugin/markdown/markdown.js"></script>
    <script src="plugin/highlight/highlight.js"></script>
    <script src="plugin/math/math.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/3.2.0/chart.min.js"></script>
    <script src="plugin/chart/plugin.js"></script>
    <script>
      Reveal.initialize({
        hash: true,
        width: 1920,
        height: 1080,
        transition: "fade",

        math: {
          mathjax:
            "https://cdn.jsdelivr.net/gh/mathjax/mathjax@2.7.8/MathJax.js",
          config: "TeX-AMS_HTML-full",
          TeX: { Macros: { RR: "{\\bf R}" } },
        },

        plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealMath],
      });
    </script>
  </body>
</html>
